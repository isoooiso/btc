# auto_predict_loop.py - –ü–û–õ–ù–û–°–¢–¨–Æ –ê–í–¢–û–ú–ê–¢–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –¶–ò–ö–õ
"""
–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤)
–∏ –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
1. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã
2. –î–æ–æ–±—É—á–∞–µ—Ç—Å—è –µ—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
3. –î–µ–ª–∞–µ—Ç –Ω–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑
4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å—ë –≤ –±–∞–∑—É
"""

import sys
from datetime import datetime
import os

import numpy as np
import joblib
import torch
import pandas as pd

from online_learning import OnlineLearner
from prediction_tracker import PredictionTracker
from data_loader import load_and_update_data
from features import build_feature_pipeline, add_realized_vol_if_missing
from config import (
    LOOKBACK,
    SCALER_PATH,
    IMPUTER_PATH,
    LGBM_MODEL_PATH,
    REGRESSION_MODEL_PATH,
    TFT_CHECKPOINT_PATH,
    TFT_TRAINING_PATH,
    STACKING_MODEL_PATH,
)


def classify_signal_strength(effective_pct: float, confidence: float, direction: str) -> str:
    """
    –ì—Ä—É–±–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞:
    - NEUTRAL: –µ—Å–ª–∏ direction —Å–æ–¥–µ—Ä–∂–∏—Ç '–ù–ï–ô–¢–†–ê–õ'
    - STRONG / MEDIUM / WEAK / VERY_WEAK –ø–æ —Å–æ—á–µ—Ç–∞–Ω–∏—é –∞–º–ø–ª–∏—Ç—É–¥—ã –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    """
    if "–ù–ï–ô–¢–†–ê–õ" in direction.upper():
        return "NEUTRAL"

    amp = abs(effective_pct)

    if amp >= 1.5 and confidence >= 80:
        return "STRONG"
    if amp >= 1.0 and confidence >= 70:
        return "MEDIUM"
    if amp >= 0.5 and confidence >= 60:
        return "WEAK"
    return "VERY_WEAK"


def main() -> bool:
    print("=" * 80)
    print("ü§ñ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –¶–ò–ö–õ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø BTC")
    print(f"   –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # === –≠–¢–ê–ü 1: –ü–†–û–í–ï–†–ö–ê –°–¢–ê–†–´–• –ü–†–û–ì–ù–û–ó–û–í ===
    print("\nüìä –≠–¢–ê–ü 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
    print("-" * 80)

    tracker = PredictionTracker()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    df_check = load_and_update_data()
    current_price_check = df_check["close"].iloc[-1]

    tracker.check_predictions(current_price_check)

    # === –≠–¢–ê–ü 2: –î–û–û–ë–£–ß–ï–ù–ò–ï (–µ—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö) ===
    print("\nüéì –≠–¢–ê–ü 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è")
    print("-" * 80)

    learner = OnlineLearner(min_samples_for_retrain=50)
    retrained = learner.run()

    if retrained:
        print("\n‚ö†Ô∏è –ú–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞! –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")

    # === –≠–¢–ê–ü 3: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ù–û–í–û–ì–û –ü–†–û–ì–ù–û–ó–ê ===
    print("\nüîÆ –≠–¢–ê–ü 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞")
    print("-" * 80)

    print("\n–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    df = load_and_update_data()

    # –ï–¥–∏–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Ñ–∏—á–µ–π –¥–ª—è LIVE
    df = build_feature_pipeline(
        df,
        mode="live",
        use_onchain=True,
        use_macro=True,
        use_trends=True,
        use_derivatives=True,
        use_orderbook_live=True,
    )

    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ realized_vol_24h
    df = add_realized_vol_if_missing(df)

    # —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –º–µ—Ç–∫–µ (low_vol / normal_vol / high_vol)
    if "vol_regime_label" in df.columns:
        current_vol_regime = df["vol_regime_label"].iloc[-1]
    else:
        current_vol_regime = "unknown"

    print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞...")

    try:
        scaler = joblib.load(SCALER_PATH)
        imputer = joblib.load(IMPUTER_PATH)

        # —Ñ–∏—á–∏: –µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–±–æ—Ä, –±–µ—Ä—ë–º –µ–≥–æ, –∏–Ω–∞—á–µ –±–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫
        if os.path.exists("data/selected_feature_cols.pkl"):
            feature_cols = joblib.load("data/selected_feature_cols.pkl")
        else:
            feature_cols = joblib.load("data/feature_cols.pkl")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        window = df.iloc[-LOOKBACK:].copy()
        latest = df.iloc[-1:].copy()

        # –û—á–∏—Å—Ç–∫–∞ inf -> NaN
        for col in feature_cols:
            if col in window.columns:
                window[col] = window[col].replace([np.inf, -np.inf], np.nan)
            if col in latest.columns:
                latest[col] = latest[col].replace([np.inf, -np.inf], np.nan)

        window_imp = imputer.transform(window[feature_cols])
        latest_imp = imputer.transform(latest[feature_cols])
        window_scaled = scaler.transform(window_imp)
        latest_scaled = scaler.transform(latest_imp)
        window_scaled = np.nan_to_num(window_scaled, nan=0.0, posinf=0.0, neginf=0.0)
        latest_scaled = np.nan_to_num(latest_scaled, nan=0.0, posinf=0.0, neginf=0.0)

        # ===== TFT =====
        tft_prob = 0.5
        try:
            from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet

            if os.path.exists(TFT_CHECKPOINT_PATH) and os.path.exists(TFT_TRAINING_PATH):
                training = joblib.load(TFT_TRAINING_PATH)
                tft = TemporalFusionTransformer.load_from_checkpoint(
                    TFT_CHECKPOINT_PATH, map_location=device
                )
                tft.eval()
                tft.to(device)

                encoder_data = pd.DataFrame(window_scaled, columns=feature_cols)
                encoder_data["target"] = 0.0
                encoder_data["time_idx"] = np.arange(LOOKBACK)
                encoder_data["group"] = 0
                decoder_data = encoder_data.iloc[[-1]].copy()
                decoder_data["time_idx"] = LOOKBACK
                full_pred_df = pd.concat([encoder_data, decoder_data], ignore_index=True)

                pred_dataset = TimeSeriesDataSet.from_dataset(
                    training, full_pred_df, predict=True, stop_randomization=True
                )
                pred_loader = pred_dataset.to_dataloader(
                    train=False, batch_size=1, num_workers=0
                )

                with torch.no_grad():
                    raw_preds = tft.predict(pred_loader, mode="quantiles")
                    if isinstance(raw_preds, torch.Tensor):
                        raw_preds = raw_preds.cpu().numpy()
                    median_pred = (
                        raw_preds[0, 0, 3] if raw_preds.ndim == 3 else raw_preds[0]
                    )
                    tft_prob = 1 / (1 + np.exp(-median_pred))
                    tft_prob = np.clip(tft_prob, 0.01, 0.99)
        except Exception as e:
            print(f"  TFT warning: {e}")

        # ===== LGBM =====
        lgbm_prob = 0.5
        try:
            lgbm = joblib.load(LGBM_MODEL_PATH)
            prob = lgbm.predict(latest_scaled)
            lgbm_prob = prob[0] if prob.ndim == 1 else prob[0, 1]
            lgbm_prob = np.clip(lgbm_prob, 0.01, 0.99)

            if os.path.exists("data/isotonic_calibrator.pkl"):
                calibrator = joblib.load("data/isotonic_calibrator.pkl")
                lgbm_prob = calibrator.transform([lgbm_prob])[0]
        except Exception as e:
            print(f"  LGBM warning: {e}")

        # ===== Regression: vol-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π -> —Ä–µ–∞–ª—å–Ω—ã–µ % =====
        regression_pct = 0.0
        try:
            reg = joblib.load(REGRESSION_MODEL_PATH)
            regression_pct_norm = reg.predict(latest_scaled)[0]
            rv_last = float(df["realized_vol_24h"].iloc[-1])
            regression_pct = float(regression_pct_norm * rv_last)
        except Exception:
            # fallback: –≥—Ä—É–±–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ—Ç LGBM
            regression_pct = float((lgbm_prob - 0.5) * 8.0)

        # ===== –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª—è =====
        weights = tracker.get_current_weights()
        tft_w = weights.get("tft_weight", 0.5)
        lgbm_w = weights.get("lgbm_weight", 0.5)

        # –õ–∏–Ω–µ–π–Ω—ã–π –±–ª–µ–Ω–¥ –∫–∞–∫ –±–∞–∑–æ–≤—ã–π final_prob
        final_prob = tft_prob * tft_w + lgbm_prob * lgbm_w

        # Stacking (–µ—Å–ª–∏ –æ–±—É—á–µ–Ω)
        stacking_used = False
        try:
            stack = joblib.load(STACKING_MODEL_PATH)
            final_prob_stack = stack.predict_proba([[tft_prob, lgbm_prob]])[0, 1]
            final_prob = final_prob_stack
            stacking_used = True
        except Exception:
            pass

        # ===== RAW –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ =====
        raw_direction = "–õ–û–ù–ì ‚¨Ü" if regression_pct > 0 else "–®–û–†–¢ ‚¨á"
        raw_confidence = (
            final_prob * 100.0 if regression_pct > 0 else (1.0 - final_prob) * 100.0
        )
        raw_confidence = float(np.clip(raw_confidence, 0.0, 100.0))

        # ===== RISK-AWARE —Å–ª–æ–π =====
        # –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø–æ —Ä–µ–∂–∏–º—É –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        vol_scale_pct = 1.0
        vol_scale_conf = 1.0

        if current_vol_regime == "low_vol":
            vol_scale_pct = 1.0
            vol_scale_conf = 1.05
        elif current_vol_regime == "normal_vol":
            vol_scale_pct = 1.0
            vol_scale_conf = 1.0
        elif current_vol_regime == "high_vol":
            vol_scale_pct = 0.7
            vol_scale_conf = 0.7
        else:  # unknown
            vol_scale_pct = 1.0
            vol_scale_conf = 1.0

        effective_pct = regression_pct * vol_scale_pct

        # –±–∞–∑–æ–≤–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ / —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        direction = raw_direction
        confidence = float(np.clip(raw_confidence * vol_scale_conf, 0.0, 100.0))

        # –ª–æ–≥–∏–∫–∞ NEUTRAL –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç–µ –∏–ª–∏ —Å–ª–∞–±–æ–º —Å–∏–≥–Ω–∞–ª–µ
        neutral = False
        # —Å–ª–∞–±—ã–π –ø–æ –∞–º–ø–ª–∏—Ç—É–¥–µ
        if abs(effective_pct) < 0.3:
            neutral = True
        # —Å–∏–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç: –º–æ–¥–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç "—Ä–æ—Å—Ç", –∞ —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å–∏–ª—å–Ω–æ –≤–Ω–∏–∑, –∏–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç
        if final_prob > 0.8 and regression_pct < 0:
            neutral = True
        if final_prob < 0.2 and regression_pct > 0:
            neutral = True

        if neutral:
            direction = "–ù–ï–ô–¢–†–ê–õ–¨–ù–û ‚ö™"
            # —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º –∫–∞–∫ "—É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –Ω–µ—Ç"
            confidence = float(
                np.clip(max(final_prob, 1.0 - final_prob) * 100.0, 0.0, 100.0)
            )
            effective_pct = 0.0

        # ===== –ò—Ç–æ–≥–æ–≤–∞—è —Ü–µ–Ω–∞ =====
        current_price = df["close"].iloc[-1]
        target_price = current_price * (1.0 + effective_pct / 100.0)

        # ===== –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞ =====
        signal_strength = classify_signal_strength(
            effective_pct=effective_pct,
            confidence=confidence,
            direction=direction,
        )

        # üëÄ –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥ –∞–Ω—Å–∞–º–±–ª—è + —Ä–∏—Å–∫ —Å–ª–æ—è

        print("\n---------------- –ê–ù–ê–õ–ò–¢–ò–ö–ê –ê–ù–°–ê–ú–ë–õ–Ø ----------------")
        print(f"TFT prob (up):          {tft_prob:.3f}")
        print(f"LGBM prob (up):         {lgbm_prob:.3f}")
        print(f"RAW reg. pct_change:    {regression_pct:+.3f}%")
        print(f"Vol regime:             {current_vol_regime}")
        print(f"Vol scales:             pct={vol_scale_pct:.2f}, conf={vol_scale_conf:.2f}")
        print(f"RAW weights:            TFT={tft_w:.3f}, LGBM={lgbm_w:.3f}")
        print(f"Stacking used:          {stacking_used}")
        print(f"Ensemble final_prob:    {final_prob:.3f} (prob —Ä–æ—Å—Ç–∞)")
        print(f"RAW direction/conf:     {raw_direction}, {raw_confidence:.1f}%")
        print(f"RISK-AWARE pct_change:  {effective_pct:+.3f}%")
        print(
            f"RISK-AWARE direction:   {direction}, confidence: {confidence:.1f}%"
        )
        print(f"Signal strength:        {signal_strength}")
        print("----------------------------------------------------")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ (final_pct ‚Äî —É–∂–µ —Ä–∏—Å–∫-–æ—Å–æ–∑–Ω–∞–Ω–Ω—ã–π)
        prediction_id = tracker.save_prediction(
            current_price=current_price,
            tft_prob=tft_prob,
            lgbm_prob=lgbm_prob,
            regression_pct=regression_pct,  # raw
            final_direction=direction,
            final_confidence=confidence,
            final_pct=effective_pct,
        )

        # === –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –î–õ–Ø –ß–ï–õ–û–í–ï–ö–ê ===
        print("\n" * 1 + "=" * 80)
        print("üéØ –ù–û–í–´–ô –ü–†–û–ì–ù–û–ó –°–û–•–†–ê–ù–Å–ù")
        print("=" * 80)
        print(f"\nüí∞ –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: ${current_price:,.2f}")
        print(f"üéØ –¶–µ–ª–µ–≤–∞—è —Ü–µ–Ω–∞ (6h): ${target_price:,.2f}")
        print(f"\nüìä –ü—Ä–æ–≥–Ω–æ–∑: {direction}")
        print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–µ (risk-aware): {effective_pct:+.2f}%")
        print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–µ (raw):        {regression_pct:+.2f}%")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:            {confidence:.1f}%")
        print(f"   –°–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞:           {signal_strength}")
        print(f"\nüíæ ID –ø—Ä–æ–≥–Ω–æ–∑–∞: {prediction_id}")
        print("‚è∞ –ü—Ä–æ–≤–µ—Ä–∫–∞: —á–µ—Ä–µ–∑ 6 —á–∞—Å–æ–≤")

        # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        tracker.show_statistics()

        print("\n" + "=" * 80)
        print("‚úÖ –¶–ò–ö–õ –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û")
        print("   –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫: —á–µ—Ä–µ–∑ 6 —á–∞—Å–æ–≤")
        print("=" * 80)

        return True

    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
