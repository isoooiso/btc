# train_tft.py
import os
import warnings

warnings.filterwarnings("ignore")

import joblib
import numpy as np
import pandas as pd
import torch

from lightning.pytorch import Trainer, seed_everything
from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet
from pytorch_forecasting.metrics import QuantileLoss

from config import (
    FUTURE_TARGET_SHORT,
    LOOKBACK,
    TFT_CHECKPOINT_PATH,
    TFT_TRAINING_PATH,
    IMPUTER_PATH,
    SCALER_PATH,
)
from data_loader import load_and_update_data
from features import (
    add_technical_indicators,
    add_multiscale_features,
    add_temporal_features,
    filter_anomalies,
    add_onchain_features,
    add_macro_features,
    add_fear_greed_index,
    add_btc_dominance,
    add_google_trends,
    add_fed_rate,
    add_additional_macro,
    add_correlations_and_external,
    add_derivatives_features,
    create_dual_target,
    create_regression_target,
)
from preprocessing import load_feature_cols, transform_with_preprocessor


# -----------------------------------------------------------
# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (—Ç–∞ –∂–µ –ª–æ–≥–∏–∫–∞, —á—Ç–æ –≤ train_core_models)
# -----------------------------------------------------------

def build_full_dataset_for_tft() -> pd.DataFrame:
    """
    –°—Ç—Ä–æ–∏–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å —Ç–µ–º–∏ –∂–µ —Ñ–∏—á–∞–º–∏ –∏ —Ç–∞—Ä–≥–µ—Ç–∞–º–∏,
    —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è LGBM/—Ä–µ–≥—Ä–µ—Å—Å–∏–∏.
    """
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è TRAIN TFT...")
    df = load_and_update_data()
    df = add_technical_indicators(df)
    df = add_multiscale_features(df)
    df = add_temporal_features(df)
    df = filter_anomalies(df)
    df = add_onchain_features(df)
    df = add_macro_features(df)
    df = add_fear_greed_index(df)
    df = add_btc_dominance(df)
    df = add_google_trends(df)
    df = add_fed_rate(df)
    df = add_additional_macro(df)
    df = add_correlations_and_external(df)
    df = add_derivatives_features(df)

    # —Ç–∞—Ä–≥–µ—Ç—ã ‚Äî –∫–∞–∫ –≤ train_core_models / backtest
    df = create_dual_target(df, short=FUTURE_TARGET_SHORT)
    df = create_regression_target(df, future=FUTURE_TARGET_SHORT)

    # —É–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç/–Ω–∞—á–∞–ª–æ –±–µ–∑ —Ç–∞—Ä–≥–µ—Ç–æ–≤
    df = df[(df["target_short"] != -1) & df["pct_change"].notna()].copy()
    print(f"–í—Å–µ–≥–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è TFT: {len(df)}")
    return df


# -----------------------------------------------------------
# 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è TimeSeriesDataSet
# -----------------------------------------------------------

def prepare_tft_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    1) –ì—Ä—É–∑–∏–º —Å–ø–∏—Å–æ–∫ —Ñ–∏—á–µ–π (—Ç–æ—Ç –∂–µ, —á—Ç–æ –¥–ª—è LGBM/—Ä–µ–≥—Ä–µ—Å—Å–∏–∏).
    2) –ü—Ä–∏–º–µ–Ω—è–µ–º –¢–ï –ñ–ï imputer + scaler, —á—Ç–æ –±—ã–ª–∏ –æ–±—É—á–µ–Ω—ã –≤ train_core_models.
    3) –°–æ–±–∏—Ä–∞–µ–º df_tft —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:
       - feature_cols (scaled)
       - 'target'  (pct_change)
       - 'time_idx'
       - 'group'
    """
    print("\n–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è TFT...")

    # --- 2.1. –≥—Ä—É–∑–∏–º —Å–ø–∏—Å–æ–∫ —Ñ–∏—á–µ–π ---
    feature_cols = load_feature_cols(df)
    print(f"–§–∏—á–µ–π –¥–ª—è TFT: {len(feature_cols)}")

    # --- 2.2. –≥—Ä—É–∑–∏–º –∏–º—å—é—Ç–µ—Ä –∏ —Å–∫–µ–π–ª–µ—Ä (–æ–±—É—á–µ–Ω—ã –≤ train_core_models.py) ---
    imputer = joblib.load(IMPUTER_PATH)
    scaler = joblib.load(SCALER_PATH)

    # --- 2.3. –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ ---
    X = df[feature_cols].copy()
    X_scaled = transform_with_preprocessor(X, imputer, scaler)

    # —Å–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π df –¥–ª—è TFT
    df_tft = pd.DataFrame(X_scaled, columns=feature_cols, index=df.index)

    # —Ç–∞—Ä–≥–µ—Ç TFT ‚Äî —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π pct_change
    df_tft["target"] = df["pct_change"].values

    # –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å (0..N-1)
    df_tft["time_idx"] = np.arange(len(df_tft))

    # –æ–¥–Ω–∞ –≥—Ä—É–ø–ø–∞ (–æ–¥–∏–Ω —Ç–∞–π–º-—Å–µ—Ä–∏–∞–ª)
    df_tft["group"] = 0

    # —É–±–∏—Ä–∞–µ–º NaN –ø–æ —Ç–∞—Ä–≥–µ—Ç—É
    df_tft = df_tft.dropna(subset=["target"]).copy()

    # üîß –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–°: —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è TimeSeriesDataSet
    df_tft = df_tft.reset_index(drop=True)

    print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä df_tft –¥–ª—è TFT: {len(df_tft)}")
    return df_tft, feature_cols



# -----------------------------------------------------------
# 3. –û–±—É—á–µ–Ω–∏–µ TFT
# -----------------------------------------------------------

def train_tft():
    seed_everything(42, workers=True)

    # 3.1. —Å—Ç—Ä–æ–∏–º –¥–∞—Ç–∞—Å–µ—Ç
    df = build_full_dataset_for_tft()
    df_tft, feature_cols = prepare_tft_dataframe(df)

    # 3.2. train/val split –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    split_idx = int(0.8 * len(df_tft))
    train_df = df_tft.iloc[:split_idx].copy()
    val_df = df_tft.iloc[split_idx:].copy()

    print(f"\nTrain size (TFT): {len(train_df)}, Val size (TFT): {len(val_df)}")

    # 3.3. —Å–æ–∑–¥–∞—ë–º TimeSeriesDataSet
    max_encoder_length = LOOKBACK
    max_prediction_length = 1  # –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º 1 —à–∞–≥ –≤–ø–µ—Ä—ë–¥ (6h pct_change)

    training = TimeSeriesDataSet(
        train_df,
        time_idx="time_idx",
        target="target",
        group_ids=["group"],
        max_encoder_length=max_encoder_length,
        max_prediction_length=max_prediction_length,
        time_varying_unknown_reals=feature_cols + ["target"],
        # –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≤–ø–µ—Ä—ë–¥ —Ñ–∏—á–∏, –µ—Å–ª–∏ –ø–æ—è–≤—è—Ç—Å—è
        time_varying_known_reals=[],
        add_relative_time_idx=True,
        add_target_scales=True,
        add_encoder_length=True,
    )

    validation = TimeSeriesDataSet.from_dataset(
        training,
        val_df,
        predict=False,
        stop_randomization=True,
    )

    train_loader = training.to_dataloader(
        train=True,
        batch_size=64,
        num_workers=0,
    )
    val_loader = validation.to_dataloader(
        train=False,
        batch_size=64,
        num_workers=0,
    )

    # 3.4. —Å–æ–∑–¥–∞—ë–º TFT –º–æ–¥–µ–ª—å
    print("\n–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º TemporalFusionTransformer...")
    tft = TemporalFusionTransformer.from_dataset(
        training,
        learning_rate=1e-3,
        hidden_size=64,
        attention_head_size=4,
        dropout=0.1,
        loss=QuantileLoss(),  # —Ä–µ–≥—Ä–µ—Å—Å–∏—è pct_change –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º
        log_interval=50,
        log_val_interval=1,
    )

    # 3.5. –∫–æ–ª–ª–±–µ–∫–∏
    ckpt_dir = os.path.dirname(TFT_CHECKPOINT_PATH)
    os.makedirs(ckpt_dir, exist_ok=True)

    checkpoint_callback = ModelCheckpoint(
        dirpath=ckpt_dir,
        filename=os.path.basename(TFT_CHECKPOINT_PATH).replace(".ckpt", ""),
        monitor="val_loss",
        save_top_k=1,
        mode="min",
    )

    early_stop_callback = EarlyStopping(
        monitor="val_loss",
        min_delta=1e-4,
        patience=5,
        mode="min",
    )

    # 3.6. Trainer
    accelerator = "gpu" if torch.cuda.is_available() else "cpu"
    trainer = Trainer(
        accelerator=accelerator,
        devices="auto",
        max_epochs=30,
        callbacks=[checkpoint_callback, early_stop_callback],
        gradient_clip_val=0.1,
    )

    print("\n–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ TFT...")
    trainer.fit(
        tft,
        train_dataloaders=train_loader,
        val_dataloaders=val_loader,
    )

    best_ckpt = checkpoint_callback.best_model_path
    if not best_ckpt:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–µ—Å.")
        trainer.save_checkpoint(TFT_CHECKPOINT_PATH)
    else:
        # –∫–æ–ø–∏—Ä—É–µ–º/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç –≤ TFT_CHECKPOINT_PATH
        if best_ckpt != TFT_CHECKPOINT_PATH:
            import shutil

            shutil.copy2(best_ckpt, TFT_CHECKPOINT_PATH)
        print(f"\n‚úÖ –õ—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç TFT —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {TFT_CHECKPOINT_PATH}")

    # 3.7. —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–∫—Ç training TimeSeriesDataSet
    joblib.dump(training, TFT_TRAINING_PATH)
    print(f"‚úÖ TimeSeriesDataSet (training) —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {TFT_TRAINING_PATH}")

    # 3.8. –±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    tft = TemporalFusionTransformer.load_from_checkpoint(TFT_CHECKPOINT_PATH)
    tft.eval()

    with torch.no_grad():
        preds = tft.predict(val_loader, mode="prediction")
    preds = preds.cpu().numpy().reshape(-1)
    true = val_df["target"].values[: len(preds)]

    mae = np.mean(np.abs(true - preds))
    print(f"\nüîç –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ TFT –Ω–∞ val: MAE pct_change ‚âà {mae:.3f}%")

    print("\nüéâ –û–±—É—á–µ–Ω–∏–µ TFT –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    train_tft()
