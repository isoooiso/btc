# diagnose_inf.py - –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê INF –í –î–ê–ù–ù–´–•
import pandas as pd
import numpy as np
from data_loader import load_and_update_data
from features import (
    add_technical_indicators, filter_anomalies, add_onchain_features,
    add_macro_features, add_multiscale_features, add_fear_greed_index, 
    add_btc_dominance, add_google_trends, add_additional_macro, 
    add_correlations_and_external, add_temporal_features, add_fed_rate
)

print("="*80)
print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê INF –í –î–ê–ù–ù–´–•")
print("="*80 + "\n")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df = load_and_update_data()
print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(df)} —Å—Ç—Ä–æ–∫\n")

# –ü–æ—à–∞–≥–æ–≤–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∏—á–µ–π —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
def check_inf(df, stage_name):
    inf_count = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()
    if inf_count > 0:
        print(f"‚ùå {stage_name}: –Ω–∞–π–¥–µ–Ω–æ {inf_count} inf –∑–Ω–∞—á–µ–Ω–∏–π")
        inf_cols = df.select_dtypes(include=[np.number]).columns[np.isinf(df.select_dtypes(include=[np.number])).any()].tolist()
        print(f"   –ö–æ–ª–æ–Ω–∫–∏ —Å inf: {inf_cols[:10]}...")  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
        return True
    else:
        print(f"‚úÖ {stage_name}: inf –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return False

print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞:\n")

df = add_technical_indicators(df)
check_inf(df, "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")

df = add_multiscale_features(df)
check_inf(df, "–ú—É–ª—å—Ç–∏–º–∞—Å—à—Ç–∞–±–Ω—ã–µ —Ñ–∏—á–∏")

df = add_temporal_features(df)
if check_inf(df, "–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏"):
    print("\nüîç –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π:")
    for col in df.columns:
        if np.isinf(df[col]).any():
            inf_count = np.isinf(df[col]).sum()
            print(f"   - {col}: {inf_count} inf –∑–Ω–∞—á–µ–Ω–∏–π")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏—è
            inf_sample = df[col][np.isinf(df[col])].head(3).values
            print(f"     –ü—Ä–∏–º–µ—Ä—ã: {inf_sample}")

df = filter_anomalies(df)
check_inf(df, "–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π")

df = add_onchain_features(df)
check_inf(df, "On-chain")

df = add_macro_features(df)
check_inf(df, "–ú–∞–∫—Ä–æ")

df = add_fear_greed_index(df)
check_inf(df, "Fear & Greed")

df = add_btc_dominance(df)
check_inf(df, "BTC Dominance")

df = add_google_trends(df)
check_inf(df, "Google Trends")

df = add_fed_rate(df)
check_inf(df, "Fed Rate")

df = add_additional_macro(df)
check_inf(df, "Additional Macro")

df = add_correlations_and_external(df)
check_inf(df, "–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ –≤–Ω–µ—à–Ω–∏–µ")

print("\n" + "="*80)
print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
print("="*80)

numeric_cols = df.select_dtypes(include=[np.number]).columns
total_inf = np.isinf(df[numeric_cols]).sum().sum()
total_nan = df[numeric_cols].isna().sum().sum()
total_cells = len(df) * len(numeric_cols)

print(f"–í—Å–µ–≥–æ —è—á–µ–µ–∫: {total_cells:,}")
print(f"Inf –∑–Ω–∞—á–µ–Ω–∏–π: {total_inf:,} ({total_inf/total_cells*100:.2f}%)")
print(f"NaN –∑–Ω–∞—á–µ–Ω–∏–π: {total_nan:,} ({total_nan/total_cells*100:.2f}%)")

if total_inf > 0:
    print("\n‚ùå –ü–†–û–ë–õ–ï–ú–ê: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã inf –∑–Ω–∞—á–µ–Ω–∏—è!")
    print("   –ù—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É –≤ features.py")
else:
    print("\n‚úÖ –û—Ç–ª–∏—á–Ω–æ! Inf –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç")

print("="*80)