# quick_predict.py - –ë–´–°–¢–†–´–ô –ü–†–û–ì–ù–û–ó –° –û–¢–°–õ–ï–ñ–ò–í–ê–ù–ò–ï–ú
import torch
from data_loader import load_and_update_data
from features import (
    add_technical_indicators, filter_anomalies, add_onchain_features,
    add_macro_features, add_multiscale_features, add_fear_greed_index, 
    add_btc_dominance, add_google_trends, add_additional_macro, 
    add_correlations_and_external, add_temporal_features, add_fed_rate
)
from predict import predict_ensemble
from prediction_tracker import PredictionTracker
import pandas as pd

print("="*80)
print("üîÆ –ë–´–°–¢–†–´–ô –ü–†–û–ì–ù–û–ó BTC —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
print("="*80 + "\n")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\n")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è tracker
tracker = PredictionTracker()

# === –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ ===
print("="*80)
print("–®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
print("="*80)

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
df_check = load_and_update_data()
current_price_for_check = df_check['close'].iloc[-1]

tracker.check_predictions(current_price_for_check)

# === –®–ê–ì 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ ===
print("\n" + "="*80)
print("–®–ê–ì 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞")
print("="*80 + "\n")

print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
df = load_and_update_data()

print("–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∏—á–µ–π...")
df = add_technical_indicators(df)
df = add_multiscale_features(df)
df = add_temporal_features(df)
df = filter_anomalies(df)
df = add_onchain_features(df)
df = add_macro_features(df)
df = add_fear_greed_index(df)
df = add_btc_dominance(df)
df = add_google_trends(df)
df = add_fed_rate(df)
df = add_additional_macro(df)
df = add_correlations_and_external(df)

# –ü—Ä–æ–≥–Ω–æ–∑ —Å –ø–æ–ª—É—á–µ–Ω–∏–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
print("\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞...\n")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è tracker
import joblib
import numpy as np
import os
from config import *

# –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
try:
    scaler = joblib.load(SCALER_PATH)
    imputer = joblib.load(IMPUTER_PATH)
    
    if os.path.exists(SELECTED_FEATURE_COLS_PATH):
        feature_cols = joblib.load(SELECTED_FEATURE_COLS_PATH)
    else:
        feature_cols = joblib.load(FEATURE_COLS_PATH)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    window = df.iloc[-LOOKBACK:].copy()
    latest = df.iloc[-1:].copy()
    
    # –û—á–∏—Å—Ç–∫–∞ inf/nan
    for col in feature_cols:
        if col in window.columns:
            window[col] = window[col].replace([np.inf, -np.inf], np.nan)
        if col in latest.columns:
            latest[col] = latest[col].replace([np.inf, -np.inf], np.nan)
    
    window_imp = imputer.transform(window[feature_cols])
    latest_imp = imputer.transform(latest[feature_cols])
    window_scaled = scaler.transform(window_imp)
    latest_scaled = scaler.transform(latest_imp)
    window_scaled = np.nan_to_num(window_scaled, nan=0.0, posinf=0.0, neginf=0.0)
    latest_scaled = np.nan_to_num(latest_scaled, nan=0.0, posinf=0.0, neginf=0.0)
    
    # TFT
    tft_prob = 0.5
    try:
        from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet
        if os.path.exists(TFT_CHECKPOINT_PATH) and os.path.exists(TFT_TRAINING_PATH):
            training = joblib.load(TFT_TRAINING_PATH)
            tft = TemporalFusionTransformer.load_from_checkpoint(TFT_CHECKPOINT_PATH, map_location=device)
            tft.eval()
            tft.to(device)
            
            encoder_data = pd.DataFrame(window_scaled, columns=feature_cols)
            encoder_data["target"] = 0.0
            encoder_data["time_idx"] = np.arange(LOOKBACK)
            encoder_data["group"] = 0
            decoder_data = encoder_data.iloc[[-1]].copy()
            decoder_data["time_idx"] = LOOKBACK
            full_pred_df = pd.concat([encoder_data, decoder_data], ignore_index=True)
            
            pred_dataset = TimeSeriesDataSet.from_dataset(training, full_pred_df, predict=True, stop_randomization=True)
            pred_loader = pred_dataset.to_dataloader(train=False, batch_size=1, num_workers=0)
            
            with torch.no_grad():
                raw_preds = tft.predict(pred_loader, mode="quantiles")
                if isinstance(raw_preds, torch.Tensor):
                    raw_preds = raw_preds.cpu().numpy()
                median_pred = raw_preds[0, 0, 3] if raw_preds.ndim == 3 else raw_preds[0]
                tft_prob = 1 / (1 + np.exp(-median_pred))
                tft_prob = np.clip(tft_prob, 0.01, 0.99)
    except:
        pass
    
    # LGBM
    lgbm_prob = 0.5
    try:
        lgbm = joblib.load(LGBM_MODEL_PATH)
        prob = lgbm.predict(latest_scaled)
        lgbm_prob = prob[0] if prob.ndim == 1 else prob[0, 1]
        lgbm_prob = np.clip(lgbm_prob, 0.01, 0.99)
        
        if os.path.exists('data/isotonic_calibrator.pkl'):
            calibrator = joblib.load('data/isotonic_calibrator.pkl')
            lgbm_prob = calibrator.transform([lgbm_prob])[0]
    except:
        pass
    
    # Regression
    regression_pct = 0.0
    try:
        reg = joblib.load(REGRESSION_MODEL_PATH)
        regression_pct = reg.predict(latest_scaled)[0]
    except:
        regression_pct = (lgbm_prob - 0.5) * 8
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –∏–∑ tracker
    weights = tracker.get_current_weights()
    final_prob = tft_prob * weights['tft_weight'] + lgbm_prob * weights['lgbm_weight']
    
    # Stacking (–µ—Å–ª–∏ –µ—Å—Ç—å)
    try:
        stack = joblib.load(STACKING_MODEL_PATH)
        final_prob = stack.predict_proba([[tft_prob, lgbm_prob]])[0, 1]
    except:
        pass
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    direction = "–õ–û–ù–ì ‚¨Ü" if regression_pct > 0 else "–®–û–†–¢ ‚¨á"
    confidence = final_prob * 100 if regression_pct > 0 else (1 - final_prob) * 100
    confidence = np.clip(confidence, 0, 100)
    
    # –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
    current_price = df['close'].iloc[-1]
    target_price = current_price * (1 + regression_pct / 100)
    
    # === –°–û–•–†–ê–ù–ï–ù–ò–ï –ü–†–û–ì–ù–û–ó–ê –í TRACKER ===
    prediction_id = tracker.save_prediction(
        current_price=current_price,
        tft_prob=tft_prob,
        lgbm_prob=lgbm_prob,
        regression_pct=regression_pct,
        final_direction=direction,
        final_confidence=confidence,
        final_pct=regression_pct
    )
    
    # –í—ã–≤–æ–¥
    print("\n" + "="*80)
    print("üéØ –ü–†–û–ì–ù–û–ó –ù–ê –°–õ–ï–î–£–Æ–©–ò–ï 6 –ß–ê–°–û–í:")
    print("="*80)
    print(f"\nüìä –ü—Ä–æ–≥–Ω–æ–∑—ã –º–æ–¥–µ–ª–µ–π:")
    print(f"   TFT prob: {tft_prob:.4f} ({'–õ–û–ù–ì' if tft_prob > 0.5 else '–®–û–†–¢'})")
    print(f"   LGBM prob: {lgbm_prob:.4f} ({'–õ–û–ù–ì' if lgbm_prob > 0.5 else '–®–û–†–¢'})")
    print(f"   Regression: {regression_pct:+.2f}%")
    
    print(f"\nüé≤ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞:")
    print(f"   TFT: {weights['tft_weight']:.3f}")
    print(f"   LGBM: {weights['lgbm_weight']:.3f}")
    
    print(f"\nüéØ –§–ò–ù–ê–õ–¨–ù–´–ô –ü–†–û–ì–ù–û–ó:")
    print(f"   –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction}")
    print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {regression_pct:+.2f}%")
    print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1f}%")
    
    print(f"\nüí∞ –¶–µ–Ω—ã:")
    print(f"   –¢–µ–∫—É—â–∞—è: ${current_price:,.2f}")
    print(f"   –¶–µ–ª–µ–≤–∞—è (6h): ${target_price:,.2f}")
    
    print("\n" + "="*80)
    print(f"üíæ –ü—Ä–æ–≥–Ω–æ–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Å ID: {prediction_id}")
    print("   –ó–∞–ø—É—Å—Ç–∏ —ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —á–µ—Ä–µ–∑ 6 —á–∞—Å–æ–≤ –¥–ª—è –∞–≤—Ç–æ–ø—Ä–æ–≤–µ—Ä–∫–∏!")
    print("="*80)
    
except Exception as e:
    print(f"–û—à–∏–±–∫–∞: {e}")
    import traceback
    traceback.print_exc()